 <!DOCTYPE html>
<html>
<head>
<title>Projects</title>
<link rel="icon" href="../favicon.ico/favicon.ico" type="../favicon.ico/favicon.ico" />
<style>

body {
 font-family: Century Gothic, sans-serif;
 color: #333333;
}

h1 {
  font-size: 35px;
}

h3 {
  font-size: 20px;
}

p {
  font-size: 15px;
}

</style>

</head>
<body>

<h1>Projects</h1>
<p>Following is (an incomplete) list of my projects: <br/></p>

<h3>Landmark Detection and Tracking (SLAM): </h3>
<img src="slam.png" alt="SLAM" height="200" width="200" align="right"> 
Implemented SLAM (Simultaneous Localization and Mapping) for a 2 dimensional world. Combining knowledge of robot sensor measurements and movement to create a map of an environment from only sensor and motion data gathered by a robot, over time. SLAM provides a way to track the location of a robot in the world in real-time and identify the locations of landmarks such as buildings, trees, rocks, and other world features. Currently expanding this work for a 3 dimensional world.
<br/>
[Github: <a href="https://github.com/siddsrivastava/SLAM-Landmark-Detection-and-Tracking"> SLAM</a>]
<br/> <br/> <br/> <br/> 

<h3>Keep it cool: </h3>
<img src="kic.PNG" alt="kic" height="250" width="350" align="left" hspace=20> 
Keep it cool is visualization tool that maps NASA's GISTEMP data on a WebGL based globe, and displays the impact of climate change on global mean temperature over the past century. This visualization work was inspired by the work done by Chrome Experiments (WebGL) and people like A. Sweeney, Yoshua Bengio and many others' work in visualizing climate change.
<br/>
[Github: <a href="https://github.com/siddsrivastava/Keep-it-cool"> Keep it cool</a>]
<br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> 

<h3>Image captioning: </h3>
<img src="ic.PNG" alt="ic" height="250" width="350" align="right"> 
In this project, a CNN-LSTM encoder-decoder model was used to generate captions for images automatically. A complex deep learning model is used comprising of two components: a Convolutional Neural Network (CNN) that transforms an input image into a set of features - encoding the information in an image into a vector (known as embedding, which is a featurized representation of the image), and an RNN that turns those features into descriptive language. 
[Github: <a href="https://github.com/siddsrivastava/Image-captioning">Image Captioning</a>]
<br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/>

<h3>Facial Keypoint Detection: </h3>
<img src="fk.png" alt="fkd" height="250" width="250" align="left"> 
Facial Keypoint detection or Landmark detection implies identifying the various keypoints present on any face. In each training and test image, there is a single face and 68 keypoints, with coordinates (x, y), for that face. These keypoints mark important areas of the face: the eyes, corners of the mouth, the nose, etc. These keypoints are relevant for a variety of tasks, such as face filters, emotion recognition, pose recognition, and so on.
[Github: <a href="https://github.com/siddsrivastava/Facial-Keypoint-Detection">Facial Keypoint Detection</a>]
<br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> 

<h3>Neural Style Transfer: </h3>
Applying encoded style of images to different images with significantly different feature vectors.
<img src="st.png" alt="st" height="350" width="1100" align="middle"> <br/>
[More examples at: <a href="https://github.com/siddsrivastava/Style-Transfer">Style Transfer</a>]
<br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> 


</body>
</html> 
